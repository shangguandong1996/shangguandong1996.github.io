<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[给女朋友写的生统资料_Part8]]></title>
    <url>%2F2019%2F08%2F31%2F%E7%BB%99%E5%A5%B3%E6%9C%8B%E5%8F%8B%E5%86%99%E7%9A%84%E7%94%9F%E7%BB%9F%E8%B5%84%E6%96%99-Part8%2F</url>
    <content type="text"><![CDATA[]]></content>
  </entry>
  <entry>
    <title><![CDATA[给女朋友写的生统资料_Part7]]></title>
    <url>%2F2019%2F08%2F31%2F%E7%BB%99%E5%A5%B3%E6%9C%8B%E5%8F%8B%E5%86%99%E7%9A%84%E7%94%9F%E7%BB%9F%E8%B5%84%E6%96%99-Part7%2F</url>
    <content type="text"><![CDATA[到目前为止，我们已经讲完了如何读取数据，如何提取数据、如何整理数据，在这一部分，我们来讲讲如何对生统的数据有一个大致的描述。 这一部分参考了《R语言实战》的7.1部分 用数据的方式呈现 一般来说，常见的数据描述方式包括均值，方差，中位数，最大值，最小值等等。R 里面都有对应的函数来检验，比如 mean，var 等等。但为了快速地了解我们手头的数据，我们就可以用 summary 和 str 这两个函数。 我们以 test2 的数据集为例。 123456789101112131415161718192021222324252627282930# 读取test2 &lt;- read.table("rawdata/test2.txt",header = T)# head也是个查看数据的方式&gt; head(test2) control low middle high1 20.79 22.22 28.56 31.932 22.91 24.74 28.67 37.943 27.21 21.53 25.28 39.764 19.34 19.66 30.28 27.945 17.85 25.89 23.13 29.656 23.79 29.10 23.47 34.23# 使用Summary&gt; summary(test2) control low middle high Min. :17.22 Min. :18.64 Min. :22.29 Min. :24.07 1st Qu.:19.35 1st Qu.:20.39 1st Qu.:25.05 1st Qu.:29.21 Median :22.60 Median :22.69 Median :28.67 Median :32.63 Mean :21.98 Mean :23.23 Mean :28.13 Mean :32.84 3rd Qu.:23.96 3rd Qu.:25.69 3rd Qu.:29.95 3rd Qu.:36.14 Max. :27.21 Max. :29.67 Max. :35.12 Max. :39.76 # 使用str&gt; str(test2)'data.frame': 15 obs. of 4 variables: $ control: num 20.8 22.9 27.2 19.3 17.9 ... $ low : num 22.2 24.7 21.5 19.7 25.9 ... $ middle : num 28.6 28.7 25.3 30.3 23.1 ... $ high : num 31.9 37.9 39.8 27.9 29.6 ... 可以看到，summary 和 str 都是对每列的数据进行了描述。summary 偏向于描述数据的统计属性，比如最小值，最大值等等。str 偏向于描述数据的结构，比如我们可以看到数据总共是 15 行，4列。每列的数据都是数值型的数据。 让我们再来看看 test1 的数据集 123456789101112131415&gt; test1 &lt;- read.table("rawdata/test1.txt",header = T)&gt; summary(test1) yield seed Min. :348 Min. :1.000 1st Qu.:362 1st Qu.:1.000 Median :376 Median :2.000 Mean :378 Mean :1.931 3rd Qu.:394 3rd Qu.:3.000 Max. :414 Max. :3.000 &gt; str(test1)'data.frame': 29 obs. of 2 variables: $ yield: int 383 406 351 400 390 361 394 395 414 382 ... $ seed : int 1 1 1 1 1 1 1 1 1 1 ... 当我们在用 Summary 和 str 看 test1 的数据集的时候，是不是感觉有那么一丝不太对。seed 那列的数据描述跟我们想的不太一样啊。事实上，还是因为没有把 seed 的那列变成因子型的变量导致的。让我们再次来做个转换。 12345678910111213&gt; test1$seed &lt;- factor(test1$seed)&gt; summary(test1) yield seed Min. :348 1:10 1st Qu.:362 2:11 Median :376 3: 8 Mean :378 3rd Qu.:394 Max. :414 &gt; str(test1)'data.frame': 29 obs. of 2 variables: $ yield: int 383 406 351 400 390 361 394 395 414 382 ... $ seed : Factor w/ 3 levels "1","2","3": 1 1 1 1 1 1 1 1 1 1 ... 这下子，是不是感觉好多了。 事实上，对于 test1 的数据集，还有一个问题就是在比较多组个体或观测时，关注的焦点经常是各组的描述性统计信息，而不是样本整体的描述性统计信息。 就像这里我们可能关注的是 test1 里面 seed1、seed2、seed3 这三种种子分别的数据类型，而不是整个 29 个观测的数据结果。关于分组变量，为了不加重大家的学习负担，我推荐可以用我们之前提到过的数据提取方法，从而分别地对数据进行描述。 因为生统的数据通常不会有多个变量这种复杂的数据结构，所以上面的方法已经足够了。如果碰到了多个变量，多个组，可以试试基本包的 aggregate() 函数 或者 tidyverse 包的 group_by 函数。 事实上，还有一种快速描述数据的函数，即 table 函数。 1234&gt; table(test1$seed) 1 2 3 10 11 8 可以看到table 可以快速地呈现各个处理所对应的重复数目。三种种子分别有10、11、8个重复。不过 table 似乎在列联表等中更为常见，这里先按下不表，后面在提到线性回归中可能会讲到。 用图画的方式呈现 人类是视觉动物，所以图画的呈现可能远比数据来的更直观。在生统中，我们通常遇见的还是 boxplot，即箱式图。箱式图对于数据格式的支持非常友好，其支持宽、长数据。 但值得注意的是，对于宽数据，直接把数据输入 boxplot 是没有问题的。因为你每列都代表一个单独的处理。虽然我不太推荐把宽数据作为画图的基本数据，因为其实在不符合各种画图包的格式，也不符合我们做线性回归、方差分析等的格式。这里 boxplot 能画可能只是一个个例。 对于长数据，我们就需要输入 formula，即告诉 boxplot 谁是 x 轴，谁是 y 轴。 让我们拿之前的 test1 和 test2数据来举例子。 12# test2的boxplotboxplot(test2) 123# test1的boxplot，我们以 yield 作为 y 轴，seed 作为 x 轴# 记得用 ？号看看 boxplot 的基本使用方法boxplot(yield ~ seed , data = test1) boxplot 的意义参见网上的解释 图片来源： Understanding Boxplots 你也可以画柱状图，用 hist 这个函数就行。这个上课应该都画过，不讲了。 顺便提一句，现在大家已经开始摈弃bar plot了，因为bar plot并不能给予我们太多的信息。相对应的，大家已经开始逐渐转向 box plot、dot plot（Scatter plot）、violin plot。如果对于画图有兴趣，大家可以去学学 ggplot2。]]></content>
      <categories>
        <category>生物医学统计课</category>
      </categories>
      <tags>
        <tag>R</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[给女朋友写的生统资料_Part6]]></title>
    <url>%2F2019%2F05%2F18%2F%E7%BB%99%E5%A5%B3%E6%9C%8B%E5%8F%8B%E5%86%99%E7%9A%84%E7%94%9F%E7%BB%9F%E8%B5%84%E6%96%99-Part6%2F</url>
    <content type="text"><![CDATA[前面我们已经讲过了在生统课上会用到基本的数据结构以及怎么来提取我们想要的数据，这一部分我们来讲讲数据的清洗。 在生统课上，我们基本上会遇到两种数据结构。一种是我把其叫做宽数据，就比如我们在第五次生统作业中，碰到的第二题的数据。 12345678910&gt; test2 &lt;- read.table("rawdata/test2.txt",header = T)&gt; head(test2) control low middle high1 20.79 22.22 28.56 31.932 22.91 24.74 28.67 37.943 27.21 21.53 25.28 39.764 19.34 19.66 30.28 27.945 17.85 25.89 23.13 29.656 23.79 29.10 23.47 34.23 这种数据列名其实是不同的处理，每一列都对应不同处理下的值。 实际上，这种数据还不能称之为真正意义上的宽数据，这里拿来指代是为了方便与长数据区分。 另一种就是长数据，也就是我上一节翻来覆去提到过的数据结构。其每一行都是一个观测值，列名则是变量名。典型的就是我们在第五次生统作业中，碰到过的第一题的数据。 123456789&gt; test1 &lt;- read.table("rawdata/test1.txt",header = T)&gt; head(test1) yield seed1 383 12 406 13 351 14 400 15 390 16 361 1 由于宽数据在线性回归，方差分析等分析中都无法被函数所识别，所以我们首先讲讲如何把宽数据转换成长数据。 gather函数转换 首先介绍的是 tidyr 包的 gather 函数。tidyr 包的安装就是我们之前讲过的方法 1install.packages("tidyr") 有点建议大家直接装 tidyverse 包，这是个各种包的合集，里面还包括了 ggplot2 等。不过有可能安不上 tidyverse ， 如果安装有问题，欢迎大家在下面提出问题。 gather 函数的使用非常方便，你只需要指定你转换后的 key 那列的列名，value 那列的列名，以及你需要转成长数据的那几列。我们以 test2 为例。 12345678910111213# 加载包library(tidyr)# 使用gahter&gt; test2_long &lt;- gather(test2, key = "Treatment_dose", value = "survive_time",control, low, middle, high)&gt; head(test2_long) Treatment_dose survive_time1 control 20.792 control 22.913 control 27.214 control 19.345 control 17.856 control 23.79 gather 函数你需要输入参数为 第一个参数是你的数据集 第二个参数是你新构建的关键列的名称（该列的内容由原先数据集的列名组成） 名字自己取，像我这里就取名为"Treatment_dose" 第三个参数是新构建的数值列的名称 名字还是自己取，我这里取名为"survive_time" 后面的几个参数都是你要用来构建关键列的那几个列名 这里就是control, low, middle, high，即原来的几个列名。 key 和 value 大家可能还是比较懵逼，但对于我们普通的生统数据，不需要太过于纠结其意义。 gather用法在转换的时候还要考虑uniq key的问题，但我们生统的数据应该也不需要考虑这一点。 也有人提到过用 reshape2 包的 melt 函数，或者基本包 transform 函数来转换。但我觉得没有 gather 这个函数直观，简单。还有，gather 转换的时候对于不等长数据的支持也比较好。就比如我们在第五次生统作业的第三题，药物 1 和 2 有 15 只小鼠，药物 3 只有 10 只老鼠。如果只是单纯地按我们之前的做法读入数据框，就会报错。 123&gt; test3 &lt;- read.table("rawdata/test3.txt",header = T)Error in scan(file = file, what = what, sep = sep, quote = quote, dec = dec, : line 11 did not have 3 elements 就是因为3列数据不等长，所以R才会报错。这时候，我们就可以设置一个参数 123456789101112131415161718&gt; test3 &lt;- read.table("rawdata/test3.txt",header = T,fill = T)&gt; test3 med1 med2 med31 40 50 602 10 20 303 35 45 1004 25 55 855 20 20 206 15 15 557 35 80 458 15 -10 309 -5 105 7710 30 75 10511 25 10 NA12 70 60 NA13 65 45 NA14 45 60 NA15 50 30 NA 然后就可以顺利地读入了，而且也可以顺利地用gather函数来整理成长数据。 1gather(test3,key = "different_med", value = "weight", med1,med2,med3) 会发现NA还是存在，但我们同样可以设置一个参数 1gather(test3,key = "different_med", value = "weight", med1,med2,med3,na.rm = T) 这样，就顺利地转换成我们需要的格式了。 基本包转换 其实，宽数据到长数据的转换，不一定需要特殊的包的函数，也可以用最基本的方法。尽管最基本的方法有些麻烦，但对于提高自己的数据转换能力还是很有帮助的。 rbind和cbind 在使用基本函数转换前，我们先来介绍两个我们以后可能会用到的函数，rbind 和 cbind。rbind是纵向合并，cbind是横向合并。具体操作我们来看一个例子 12345678910111213141516171819202122232425&gt; data1 &lt;- data.frame(A1 = sample(1:10,3),+ A2 = sample(1:10,3),+ A3 = sample(1:10,3))&gt; data1 A1 A2 A31 3 6 22 7 9 53 5 10 4&gt; data2 &lt;- data.frame(B1 = sample(10:20,3),+ B2 = sample(10:20,3),+ B3 = sample(10:20,3))&gt; data2 B1 B2 B31 15 17 142 13 14 113 17 15 12&gt; rbind(data1,data2)Error in match.names(clabs, names(xi)) : names do not match previous names&gt; cbind(data1,data2) A1 A2 A3 B1 B2 B31 3 6 2 15 17 142 7 9 5 13 14 113 5 10 4 17 15 12 可以看到rbind需要两个数据框有同样的变量（同样的列名），cbind则需要两个数据框的行数是一样的。 rbind尽管需要两个数据框有同样的变量，但顺序不一定要一样，比如 12345678910111213141516&gt; data3 &lt;- data.frame(A1 = sample(10:20,3),+ A3 = sample(10:20,3),+ A2 = sample(10:20,3))&gt; data3 A1 A3 A21 10 12 142 11 20 203 15 14 19&gt; rbind(data1,data3) A1 A2 A31 3 6 22 7 9 53 5 10 44 10 14 125 11 20 206 15 19 14 这里data1和data3的列名是一样的，但顺序是不一样的，但rbind还是可以合并。 关于rbind和cbind，《R语言实战》4.9也有提到，大家可以去看看 数据转换 介绍完了rbind和cbind，我们就可以来转换数据框了。我用test2做例子 1234567891011121314151617&gt; test2 control low middle high1 20.79 22.22 28.56 31.932 22.91 24.74 28.67 37.943 27.21 21.53 25.28 39.764 19.34 19.66 30.28 27.945 17.85 25.89 23.13 29.656 23.79 29.10 23.47 34.237 22.60 18.93 28.88 32.638 18.53 18.64 29.62 29.139 23.23 26.39 24.82 39.6210 20.14 25.49 34.64 36.1511 26.71 20.43 22.29 28.8512 19.36 22.69 29.22 24.0713 17.22 29.67 25.63 29.2914 24.13 20.36 35.12 35.2415 25.85 22.74 32.32 36.13 宽数据转换成长数据，本质上就像堆积木一样。你把每一列的数据拿出来，变成一块积木，然后你就一层层地堆起积木，最后就形成了长数据。是不是感觉特别像rbind干的事情？没错，我们这里就用rbind来构建长数据。 123456789control &lt;- data.frame(Treatment_dose = rep("control",15), survive_time = test2$control)low &lt;- data.frame(Treatment_dose = rep("low",15), survive_time = test2$low)middle &lt;- data.frame(Treatment_dose = rep("middle",15), survive_time = test2$middle)high &lt;- data.frame(Treatment_dose = rep("high",15), survive_time = test2$high)rbind(control,low,middle,high) 大家可能是一遍遍地打了以上的代码，机智的小伙伴可能还是复制粘贴的，然后把变量名改一下。不过，实际上我们可以用函数来解决这些重复操作的问题。函数这一部分就留待后面讲了。 双因素ANOVA的数据格式整理 在第五次生统作业的最后一题，我们需要考虑的是双因素ANOVA分析。但word文件里面的表格却不是一个双因素ANOVA的格式。让我们来看看如何利用上面讲过的内容，把它变成一个能让 aov 读入的双因素AONVA。 首先复制粘贴A1，A2，A3三列数据到txt文件中，然后读入R中。 123456789&gt; test4 &lt;- read.table("rawdata/test4.txt",header = T)&gt; head(test4) A1 A2 A31 282.1 296.7 300.12 264.2 318.0 307.53 274.2 295.3 294.24 276.4 292.8 312.05 283.7 304.5 300.26 288.0 305.9 292.6 然后转换成长数据框 1test4_long &lt;- gather(test4, key = temperature, value = weight, A1, A2, A3) 但这样还不够，这里只有单因素，即饲养温度这一列的信息，还没有饲料的信息。所以我们要自己加上一列饲料的信息。 123456789101112feed &lt;- c(rep("B1",10),rep("B2",10))test4_data &lt;- cbind(feed,test4_long)head(test4_data)&gt; head(test4_data) feed temperature weight1 B1 A1 282.12 B1 A1 264.23 B1 A1 274.24 B1 A1 276.45 B1 A1 283.76 B1 A1 288.0 这样就变成了双因素的ANOVA格式，可以顺利让aov函数读入了。 123456789&gt; test4_aov &lt;- aov(weight ~ feed * temperature, data = test4_data)&gt; summary(test4_aov) Df Sum Sq Mean Sq F value Pr(&gt;F) feed 1 127 127 1.589 0.213 temperature 2 9080 4540 56.809 5.22e-14 ***feed:temperature 2 17 9 0.108 0.897 Residuals 54 4316 80 ---Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1]]></content>
      <categories>
        <category>生物医学统计课</category>
      </categories>
      <tags>
        <tag>R</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[给女朋友写的生统资料_Part5]]></title>
    <url>%2F2019%2F05%2F11%2F%E7%BB%99%E5%A5%B3%E6%9C%8B%E5%8F%8B%E5%86%99%E7%9A%84%E7%94%9F%E7%BB%9F%E8%B5%84%E6%96%99-Part5%2F</url>
    <content type="text"><![CDATA[之前我们已经了解了如何去提取行、列数据。这部分我们讲讲如何筛选自己想要的数据。生统常见的一个数据提取问题就是，提取某某处理的那部分数据进行一些检验。比如，在有3种种子的数据中，提取出1号种子对应的数据。这时候，尽管我们可以根据1号种子的数字索引来提取，但这终归不是一个好的方法，因为一旦数据是打乱的，我们就无法知道正确的数字索引，从而进行提取了。所以，这时候，我们就应该使用我们之前讲过的逻辑运算符来进行操作。 顺便提下，我们之前在介绍数据框的时候，把行叫做观测，而把列叫做变量。所以我们在提取行的时候，就是在提取我们感兴趣的观测，而在提取列的时候，就是在提取我们感兴趣的变量。为什么我要翻来覆去地说这个呢，是因为我觉得以行作为观测，列作为变量是一个比较好的呈现数据的方式，也是后面很多我们生统要用到的包需要的格式。也是后面我们在说长宽数据转换时候要再次提到的一点。我们再来看一下糖尿病人的例子。 1234567891011&gt; patientID &lt;- c(1, 2, 3, 4)&gt; age &lt;- c(25, 34, 28, 52)&gt; diabetes &lt;- c("Type1", "Type2", "Type1", "Type1")&gt; status &lt;- c("Poor", "Improved", "Excellent", "Poor")&gt; patientdata &lt;- data.frame(patientID, age, diabetes, status)&gt; patientdata patientID age diabetes status1 1 25 Type1 Poor2 2 34 Type2 Improved3 3 28 Type1 Excellent4 4 52 Type1 Poor 这里是 4 行，就是 4 个观测值，4 个病人。这里有 4 列，4 个变量，就是用 4 个不同地指标去衡量了这些病人。当然，我们也会遇见不是这样格式的数据，比如我们在第五次生统作业上遇见的那个用药的数据集 123456789&gt; test2 &lt;- read.table("rawdata/test2.txt",header = T)&gt; head(test2) control low middle high1 20.79 22.22 28.56 31.932 22.91 24.74 28.67 37.943 27.21 21.53 25.28 39.764 19.34 19.66 30.28 27.945 17.85 25.89 23.13 29.656 23.79 29.10 23.47 34.23 这个数据集是 15 行，4 列。但我们并不能说我们做了 15 个观测，应用了 4 个变量。实际上，我们根据题目可知，总共是 60 只小鼠，只用了 1 个变量，即用药的浓度。你会发现这个数据集的每一行都不是同一只老鼠，但前面的糖尿病人数据集，每一行都是同一个病人，所以我们可以说每一行都是一个观测。 初次学 R 的人，对于这种数据的结构可能会感到困惑。不过不要紧，数据处理多了，就会慢慢清晰起来。 顺便提一下，现在生物学的数据跟传统社会学的数据有一个很大的不同就是，社会学的数据往往是低维度，高观测，而生物学的数据则恰好相反，是高维度，低观测的。这里的维度指的就是变量。举个例子，比如你要分发问卷给别人来统计大家对你的产品感不感兴趣，你可能在问卷上只有 2 个问题（2个变量，2个维度），但你却分发给了 1w 个人（1w 个 观测）。生物学的例子就好比，你对 100 个植株进行了 50w 个SNP位点的分析，这里就是 100 个观测，50w 的维度。数据结构的不同，就会导致分析方法的不同。 由于生统的数据列数最多也就 4,5 列，加上整列的提取并不需要逻辑运算符，所以后面的提取不涉及到列的提取。同时，为了让大家加深印象，我会交叉地用行以及观测这两个名词。 利用 [] 来提取感兴趣的观测 我们之前在向量里面提到过，如何提取符合条件的数据，这里运用的方法也是一样的，也是利用 which 或者 TRUE 来提取。不过在提取数据框数据的时候，我有一个小建议，就是分步完成你的提取任务。我们还是拿糖尿病人的数据集为例子。比如我们希望提取出年龄大于 30 岁的糖尿病人的数据。 12345678910111213141516171819202122# 先得到索引&gt; patientdata$age &gt; 30[1] FALSE TRUE FALSE TRUE&gt; which(patientdata$age &gt; 30)[1] 2 4# 把索引输入 [] 里面&gt; patientdata[patientdata$age &gt; 30,] patientID age diabetes status2 2 34 Type2 Improved4 4 52 Type1 Poor&gt; patientdata[which(patientdata$age &gt; 30),] patientID age diabetes status2 2 34 Type2 Improved4 4 52 Type1 Poor# 有时候嫌得到索引那步比较长，就可以把索引结果存为一个变量&gt; result &lt;- patientdata$age &gt; 30&gt; patientdata[result,] patientID age diabetes status2 2 34 Type2 Improved4 4 52 Type1 Poor patientdata$age &gt; 30 提取出来的索引值顺利能够放入数据框 [] 的逗号前面是因为我们之前提到过，数据框每列是等长的。想象下，我们有 4 个观测，我们我们用 patientdata$age 提取出来的，实际上是一串有 4 个值的向量，我们对向量进行了逻辑运算符，然后得到了 4 个 TRUE 或者 FALSE值，然后我们就可以把这些 TRUE 或者 FALSE 值和我们的观测一一对应。从而提出我们想要的观测。 事实上，在利用索引提取的时候，我还犯了个小错误，就是把索引输入到了错误的数据框里面，但并没有报错。 123456789&gt; test2[result,] control low middle high2 22.91 24.74 28.67 37.944 19.34 19.66 30.28 27.946 23.79 29.10 23.47 34.238 18.53 18.64 29.62 29.1310 20.14 25.49 34.64 36.1512 19.36 22.69 29.22 24.0714 24.13 20.36 35.12 35.24 这个故事告诉我们的是，索引得到的只是一串数字，他并不跟你产生这个索引结果的数据集有一毛钱的关系。 不要认为 R 的命令是黑箱，一步步地去拆解命令，你就可以很清晰地理解。 如果我们想要两个条件呢，即年龄大于30岁，且犯的是 Type I 型糖尿病呢。年龄大于 30 用的是 &gt; ，I 型糖尿病用的是等于 == ,那且是什么呢。就是我们之前提到的与或非了。 运算符 描述 x | y x或y x &amp; y x和（且）y 非的话是 !，不等于是 != 。不过我们估计是用不到的，所以我这里也就不讲了。 再次来提取我们想要的观测 123456789101112# 先得到索引&gt; patientdata$age &gt; 30[1] FALSE TRUE FALSE TRUE&gt; patientdata$diabetes == "Type1"[1] TRUE FALSE TRUE TRUE&gt; patientdata$age &gt; 30 &amp; patientdata$diabetes == "Type1"[1] FALSE FALSE FALSE TRUE# 提取&gt; patientdata[patientdata$age &gt; 30 &amp; patientdata$diabetes == "Type1",] patientID age diabetes status4 4 52 Type1 Poor 我们还可以在提取我们想要的观测的同时，提取一部分变量（列）出来 1234&gt; patientdata[patientdata$age &gt; 30,c("age","status")] age status2 34 Improved4 52 Poor 利用subset来提取 前面的那番操作大家可能会感觉写的有点长，那有没有一些简写呢，事实上是有的。你可以利用 R 基本包的 subset 函数来进行跟上面一模一样的操作。 别忘了用 ？ 来看看这个函数 有些人可能会提到用 attach 这个函数把数据框添加到 R 的搜索路径中，但实际上我不太推荐这样，因为一旦你要完成有许多个数据框的作业，而你又忘了detach，那么很有可能造成你不同数据框的不同变量之间的混淆。 subset 第一个要输入的参数是你的数据框，第二个要输入的参数是你对于观测（行）的筛选，可以用逻辑运算符串联，第三个可选择输入的是你要选择的列（变量）。跟之前一样的筛选条件，不过这次用的是 subset 函数。 123456789101112131415# 年龄大于30岁&gt; subset(patientdata, age &gt; 30) patientID age diabetes status2 2 34 Type2 Improved4 4 52 Type1 Poor# 年龄大于30，且 I 型糖尿病&gt; subset(patientdata, age &gt; 30 &amp; diabetes == "Type1") patientID age diabetes status4 4 52 Type1 Poor# 年龄大于30，且 I 型糖尿病的病人的年龄和病情&gt; subset(patientdata, age &gt; 30 &amp; diabetes == "Type1",c("age","status")) age status4 52 Poor]]></content>
      <categories>
        <category>生物医学统计课</category>
      </categories>
      <tags>
        <tag>R</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[给女朋友写的生统资料_Part4]]></title>
    <url>%2F2019%2F05%2F10%2F%E7%BB%99%E5%A5%B3%E6%9C%8B%E5%8F%8B%E5%86%99%E7%9A%84%E7%94%9F%E7%BB%9F%E8%B5%84%E6%96%99-Part4%2F</url>
    <content type="text"><![CDATA[上一节我们讲到了一些向量提取的操作。这一部分我们会讲一些数据框提取的操作。在R里面，数据框提取的基础操作跟向量很相似，还是以 [] 符号为基础。不过由于数据框是一个二维的数据结构，即有行与列，所以我们要以 dataframe[行索引, 列索引] 这种操作来提取数据框中的元素。 由于生统的数据一般只有两列，且比较长，可能不太适合演示，所以我这会用的还是之前糖尿病人的那个数据框。 1234567891011&gt; patientID &lt;- c(1, 2, 3, 4)&gt; age &lt;- c(25, 34, 28, 52)&gt; diabetes &lt;- c("Type1", "Type2", "Type1", "Type1")&gt; status &lt;- c("Poor", "Improved", "Excellent", "Poor")&gt; patientdata &lt;- data.frame(patientID, age, diabetes, status)&gt; patientdata patientID age diabetes status1 1 25 Type1 Poor2 2 34 Type2 Improved3 3 28 Type1 Excellent4 4 52 Type1 Poor 这次的内容参考了《R语言实战》的 4.10 部分，推荐大家可以去看一看。 数据框列的提取 根据坐标提取 跟我们之前介绍的向量读取差不多，也是可以利用坐标来读取。我们用坐标来提取第二列，即病人的年龄。 12&gt; patientdata[,2][1] 25 34 28 52 我们前面提到，逗号前面部分代表的是行索引（坐标可能更直白一点，但索引可能更正式一点，我还是用索引吧），逗号后面代表你要提取的列的索引。如果行的索引信息是缺失的话，那么就 R 就会默认你选择所有行。所以这里提取出了所有的 4 个病人的年龄。 根据列名提取 但这种坐标信息的提取是比较麻烦的，尤其是对于很多列的数据。你可能数不清你想要的那一列在第几列上。事实上，由于数据框的特殊数据格式，对于列的提取，也有了特殊的提取方式。因为数据框是一个二维数据结构，有行有列。意味着我们有行名和列名。所以在提取列的时候，我们也可以把列名放入原本数字索引在的地方，也可以达到跟数字索引提取同样的效果。 12&gt; patientdata[,"age"][1] 25 34 28 52 这里我们知道了我们的列名叫 age ，所以我们就把 age 加引号放入原本坐标在的那个地方，也顺利地提取出来了第二列，即病人的年龄。 $符号提取 数据框的提取还有一个简单的方式，就是在数据框后面加 $ 符号，然后就会自动跳出你的列名，你只要选择你想要的列名也可以顺利的提取出来。 12&gt; patientdata$age[1] 25 34 28 52 提取多列 多于多列数据的提取，还是用到我们上面提到的提取方法。 1234567891011121314151617# 数字索引提取&gt; patientdata[,c(2,4)] age status1 25 Poor2 34 Improved3 28 Excellent4 52 Poor# 列名提取&gt; patientdata[,c("age","status")] age status1 25 Poor2 34 Improved3 28 Excellent4 52 Poor# $符号可能不行 事实上，在提取列的时候，还有一个小问题，可能大家并没有发现。就是我们在提取单列的时候，得到的是一个向量型的结果，但我们在提取多列的时候，得到的是一个数据框型的结果。 12345&gt; class(patientdata[,"age"])[1] "numeric"&gt; class(patientdata[,c("age","status")])[1] "data.frame" 这是因为 R 会在你提取单列的时候，自动将得到的单列进行降维，将数据框变成向量。如果你并不想让数据进行降维，可以设置 drop = F。 123456789&gt; patientdata[,"age",drop = F] age1 252 343 284 52&gt; class(patientdata[,"age",drop = F])[1] "data.frame" 另一种在提取单列的时候，不降维的方法，就是你不遵循 [行索引，列索引] 这种格式，而是直接输入列索引，就像下面那样 12345678910111213141516&gt; patientdata[2] age1 252 343 284 52&gt; patientdata["age"] age1 252 343 284 52&gt; class(patientdata["age"])[1] "data.frame" 我个人不太推荐在生统做的时候用这个方式，还是建议老老实实按逗号的方式来提取，因为这样可能比较符合你的编程习惯。 但这种提出单列数据，自动降维的情况，对于我们生统是比较好的。因为像你后面做正态性检验等等，本质上你输入的应该是一串数值型的向量，而非是一个数据框。 数据框行的提取 行的提取跟列的提取很像，无非就是索引放在逗号前面。 123456789# 根据数字索引&gt; patientdata[1,] patientID age diabetes status1 1 25 Type1 Poor# 根据行名&gt; patientdata["1",] patientID age diabetes status1 1 25 Type1 Poor 大家可能会感到疑惑，1 和 "1" 难道不是一个东西么，事实上并不是。由于我们这里并没有给数据框赋予常见的那种行名，所以 R 会自动以数字即行号作为数据框的行名。所以 "1" 代表的其实是行名。这里为了更加清楚地展示，我们用人名来表示糖尿病人的行名。 1234567891011121314# rownames可以赋予行名rownames(patientdata) &lt;- c("Paul","James","Wade", "Antony")&gt; patientdata patientID age diabetes statusPaul 1 25 Type1 PoorJames 2 34 Type2 ImprovedWade 3 28 Type1 ExcellentAntony 4 52 Type1 Poor# 根据行名&gt; patientdata["Paul",] patientID age diabetes statusPaul 1 25 Type1 Poor 其实生统的作业不太会让你对某一行进行提取，更多的是提取出符合某一条件的几行来。这个就要涉及到我们之前讲到过的逻辑运算符了，这部分我们下一节再讲。 行列的提取 学会了提取列，也学会了提取行，行列就是你在 [] 里面，逗号前后都加上索引。但这个可能在生统中用处不大。 1234&gt; patientdata[1:2,2:3] age diabetes1 25 Type12 34 Type2]]></content>
      <categories>
        <category>生物医学统计课</category>
      </categories>
      <tags>
        <tag>R</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[给女朋友写的生统资料_Part3]]></title>
    <url>%2F2019%2F05%2F09%2F%E7%BB%99%E5%A5%B3%E6%9C%8B%E5%8F%8B%E5%86%99%E7%9A%84%E7%94%9F%E7%BB%9F%E8%B5%84%E6%96%99-Part3%2F</url>
    <content type="text"><![CDATA[因为生统中经常需要用到一些数据的提取，比如提取某一处理来做正态性检验等等。这些数据的提取本质上就是对某一行或者某一列的提取。所以这一部分我们来讲讲常见的数据提取。 R 里面的逻辑运算符 在讲数据提取之前，我们可能需要先了解一些逻辑运算符的基本知识。只有掌握了这些基本知识，才可以在后面灵活地提取出你想要的数据。 这一部分的内容参考了《R语言实战》的 4.3 部分，推荐大家去看看看 我们生统用到的逻辑运算符通常是大于，小于以及等于。符号分别是 运算符 描述 &lt; 小于 &lt;= 小于等于 &gt; 大于 &gt;= 大于等于 == 等于（注意等于并不是 = ，而是 == 。因为一个等号表达的是赋值或者传入参数） 当你利用逻辑运算符讲一个向量与数字进行比较的时候，R 就会返回给你 TRUE 或者 FALSE。 123&gt; vector_0 &lt;- c(1,2,3,4)&gt; vector_0 &gt; 2[1] FALSE FALSE TRUE TRUE 可以看到，凡是大于 2 的，都标明了 TRUE 。值得一提的是，等于不仅仅可以跟数字进行比较，还可以跟字符串进行比较。这在后面对数据框进行数据提取的时候，很有帮助。 12345&gt; vector_1 &lt;- c(rep("A",2),rep("B",5))&gt; vector_1[1] "A" "A" "B" "B" "B" "B" "B"&gt; vector_1 == "A"[1] TRUE TRUE FALSE FALSE FALSE FALSE FALSE 实际上，R 里面还会有与、或、非等逻辑运算符。这对于数据框的提取也是很有帮助的，这个留待我们后面再讲。 向量的数据提取 讲完了逻辑运算符，我们就可以来提取数据了。我们之前介绍了两种生统常见的数据格式，一种是向量，另一种是数据框。我们这次先讲讲如何对向量来进行数据提取。 直接利用坐标提取 在 R 中最基本的数据提取手段就是利用 [] 这个符号。而在利用 [] 这个符号的时候，最简单的提取方式就是根据坐标进行提取了。我们先来尝试一下。 123456789101112131415161718# 创建一个向量&gt; vector_2 &lt;- c(1:10)&gt; vector_2 [1] 1 2 3 4 5 6 7 8 9 10 # 让我们提取第1个数据，注意 R 是以 1 开头的，而不是以 0 开头的。&gt; vector_2[1][1] 1# 提取第2,3,4个数据&gt; vector_2[2:4][1] 2 3 4# 提取第2,5个数据&gt; vector_2[2,5]Error in vector_2[2, 5] : incorrect number of dimensions&gt; vector_2[c(2,5)][1] 2 5 可以看到，我们在一开始提取 2,5 的时候，R 给了我们报错。是因为向量是一个一维的数据结构，而 [2,5] 这种提取适合的是数据框这种二维的数据结构，这一点我们在后面提取数据框数据的时候会提到。 简单来说，对于向量这种一维数据结构的提取，你并不能在 [] 里面使用逗号。所以，你如果想要提取不连续的坐标，就可以把不连续的坐标变成向量的形式放入 [] 里面。 利用which命令来提取 利用坐标的方式来提取有时候局限性会很大，因为有时候数据会很乱，利用坐标提取并没有什么用。比如下面的数据 1234# sample等命令我们会在后面生统常见的命令那边提到&gt; vector_3 &lt;- sample(1:100,10)&gt; vector_3 [1] 31 24 61 36 65 44 60 3 74 8 如果我们想要提取这里面大于60的数字，我们用肉眼观察，然后得到坐标的方式就比较麻烦。这时候我们就可以让 R 来代替我们找到那些大于 60 的数字的坐标。 这里我们用到的是 which 命令。 12&gt; which(vector_3 &gt; 60)[1] 3 5 9 这样我们就得到了大于 60 的数字的坐标了。然后再传入 [] 里面，这样就可以跟之前利用坐标一样来提取数据了。 12&gt; vector_3=3[which(vector_3 &gt; 60)][1] 61 65 74 利用TRUE和FALSE来进行提取 除了用 which命令来提取，我们还可以利用 TRUE 和 FALSE 来进行提取。 1234&gt; vector_3 &gt; 60 [1] FALSE FALSE TRUE FALSE TRUE FALSE FALSE FALSE TRUE FALSE&gt; vector_3[vector_3 &gt; 60][1] 61 65 74 因为 TRUE 在 R 中和 T 是等价的，后面加参数的时候也是同理的。所以我在后面就会用 T 代表 TRUE了，FALSE 同理。 对于 TRUE 和 FALSE 这个类型的结果来说，有一个小彩蛋。就是我们可以把 T 和 F 传入 mean 和 sum 里面。 1234567# 统计有多少是大于 60 的。&gt; sum(vector_3 &gt; 60)[1] 3# 统计有百分之多少是大于 60 的。&gt; mean(vector_3 &gt; 60)[1] 0.3 可以看到，有 3 个数据是大于60，有 30% 的数据是大于60的。这对于大量数据的整体描述是一个非常好的小技巧。 参考文章： 《R语言实战》4.3 下一节我会讲讲如何对数据框进行提取操作。]]></content>
      <categories>
        <category>生物医学统计课</category>
      </categories>
      <tags>
        <tag>R</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[给女朋友写的生统资料_Part2]]></title>
    <url>%2F2019%2F05%2F08%2F%E7%BB%99%E5%A5%B3%E6%9C%8B%E5%8F%8B%E5%86%99%E7%9A%84%E7%94%9F%E7%BB%9F%E8%B5%84%E6%96%99-Part2%2F</url>
    <content type="text"><![CDATA[R里面有许多数据类型，跟生统课相关的就是数值型，字符型，逻辑型了。而R也有很多数据结构，包括标量、向量、矩阵、数组、数据框和列表等。跟生统课上相关的就是向量、数据框这两种了。 后面的一些内容会借鉴《R语言实战》中的内容，推荐大家可以去看看这本书的2.1 ，2.2部分。 向量 向量是用于存储数值型、字符型或逻辑型数据的一维数组。 同一向量中无法混杂不同模式的数据。 即不能把数值型、字符串型、逻辑型的混起来放入同一向量中。 让我们来创建一个向量 123456789# 创建向量a &lt;- c(1, 2, 5, 3, 6, -2, 4)b &lt;- c(&quot;one&quot;, &quot;two&quot;, &quot;three&quot;)c &lt;- c(TRUE, TRUE, TRUE, FALSE, TRUE, FALSE)# 查看向量的数据类型class(a)class(b)class(c) 对于数值型的向量创建，使用 : 可以帮助我们直接创建多个数字。这一点对于我们后面在数据框里面提取数值很有帮助。 12&gt; c(1:10) [1] 1 2 3 4 5 6 7 8 9 10 如果想要重复地创建某些值，就可以考虑 rep 函数。这一点对于后面我们给数据框添加列，或者添加列名行名可能会有帮助。 12345# 可以用?rep来查询其具体用法&gt; rep("A",3)[1] "A" "A" "A"&gt; rep(c("A","B"),3)[1] "A" "B" "A" "B" "A" "B" 如果想要间隔地创建数字，可以考虑用seq 1234# 隔3个数创建数字# 起始数字为1，终止数字为13，间隔为3个数字&gt; seq(1,13,3)[1] 1 4 7 10 13 数据框 数据框是一个二维数据结构，有行和列。一般来说，我们会将行表示观测，列表示变量 数据框可以放入不同类型的文件 一般来说，生统中的数据框是不需要自己创建的，只需要读入就行。用 read.table 读进来就已经是个数据框了。 123&gt; test1 &lt;- read.table("rawdata/test1.txt",header = T)&gt; class(test1)[1] "data.frame" 12345678&gt; head(test1) yield seed1 383 12 406 13 351 14 400 15 390 16 361 1 我们可以对这个数据框进行一些探索。 首先看下这个数据框是几行几列的 123456&gt; dim(test1)[1] 29 2&gt; nrow(test1)[1] 29&gt; ncol(test1)[1] 2 发现是一个 29 X 2 的数据框。然后我们可以看下我们数据框的行名和列名是什么。 12345678# 提取行名&gt; rownames(test1) [1] "1" "2" "3" "4" "5" "6" "7" "8" "9" "10" "11" "12" "13" "14" "15" "16" "17" "18" "19"[20] "20" "21" "22" "23" "24" "25" "26" "27" "28" "29"# 提取列名&gt; colnames(test1)[1] "yield" "seed" 我们也可以对行名和列名进行更改 123&gt; colnames(test1) &lt;- c("A","B")&gt; colnames(test1)[1] "A" "B" 当然我们也可以自己来创建一个数据框。用到的是 data.frame 函数。 12345678910111213141516171819202122# R语言实战的例子&gt; patientID &lt;- c(1, 2, 3, 4)&gt; age &lt;- c(25, 34, 28, 52)&gt; diabetes &lt;- c("Type1", "Type2", "Type1", "Type1")&gt; status &lt;- c("Poor", "Improved", "Excellent", "Poor")&gt; patientdata &lt;- data.frame(patientID, age, diabetes, status)&gt; patientdata patientID age diabetes status1 1 25 Type1 Poor2 2 34 Type2 Improved3 3 28 Type1 Excellent4 4 52 Type1 Poor# 自己来一个例子&gt; data.frame(A = c(rep(1,2),rep(2,2),rep(3,2)), B = rep("test", 6)) A B1 1 test2 1 test3 2 test4 2 test5 3 test6 3 test 需要注意的是，数据框跟列表不一样，数据框里面的每一列都必须是等长的。像我这里就是 2 个 A ，2 个 B ， 2 个 C ，再加上 6 个 test 。 如果不等长就有可能会报错。也有可能不报错，用 NA 或者其他的值填充了。这个后面可能会提到。 因子 在我看来，因子的作用是为了对变量进行分类。就比如我们在做AONVA分析的时候，我们会做多种处理，那么我们就可以认为这些处理每个都是一类。拿上面的例子举例。 123456&gt; patientdata patientID age diabetes status1 1 25 Type1 Poor2 2 34 Type2 Improved3 3 28 Type1 Excellent4 4 52 Type1 Poor 这里的糖尿病类型 Diabetes，有两种类型，分别是 Type1 和 Type2 。病情Status 有三种类型，分别是 poor、 improved、 excellent。所以这两列所含有的数据就是因子型的数据。 值得注意的是，R在构建数据框的时候，会自动将所有字符串类型的值转换成因子。我们可以看下 12345678&gt; patientdata$diabetes[1] Type1 Type2 Type1 Type1Levels: Type1 Type2&gt; patientdata$status[1] Poor Improved Excellent Poor Levels: Excellent Improved Poor&gt; patientdata$patientID[1] 1 2 3 4 如果这里有 Levels ，就代表这里的数据是因子。可以看到，patientID由于是数值型的变量，所以并没有自动地转换成因子。 我们同样也可以用 class 来看下类别。 12345&gt; class(patientdata$diabetes)[1] "factor"&gt; class(patientdata$patientID)[1] "numeric" 但有时候，字符串变量自动转换成因子也不是所有都对的，比如一开始我们有name这一列。 1234567891011121314151617181920&gt; patientID &lt;- c(1, 2, 3, 4)&gt; age &lt;- c(25, 34, 28, 52)&gt; diabetes &lt;- c("Type1", "Type2", "Type1", "Type1")&gt; status &lt;- c("Poor", "Improved", "Excellent", "Poor")&gt; names &lt;- c("Paul","James","Wade", "Antony")&gt; patientdata &lt;- data.frame(patientID, age, diabetes, status,names)&gt; patientdata patientID age diabetes status names1 1 25 Type1 Poor Paul2 2 34 Type2 Improved James3 3 28 Type1 Excellent Wade4 4 52 Type1 Poor Antony# 看下 names 的类别&gt; class(patientdata$names)[1] "factor"&gt; patientdata$names[1] Paul James Wade AntonyLevels: Antony James Paul Wade 我们会发现 R 自动地将 names 这一列也变成了因子。但实际上，名字是独一无二的，并不是一个分类变量。所以，我们不应当将其变成一个 factor 。不过，你会发现，如果是这一列是后添加上去的，就不会自动转成因子。 123456789101112# 这个操作可以自动加上一列名为name_new的列patientdata$names_new &lt;- c("Paul","James","Wade", "Antony")&gt; patientdata patientID age diabetes status names names_new1 1 25 Type1 Poor Paul Paul2 2 34 Type2 Improved James James3 3 28 Type1 Excellent Wade Wade4 4 52 Type1 Poor Antony Antony&gt; patientdata$names_new[1] "Paul" "James" "Wade" "Antony" 让我们再来看下我们在第五次生统作业的第一题的数据。 1234&gt; class(test1$yield)[1] "integer"&gt; class(test1$seed)[1] "integer" 明明我们的seed代表的是处理类别，为什么却不是一个因子呢。因为 seed 那一列是数值型的变量，所以 R 并不会自动地将其转换成因子。但如果不转换成因子的话，就可能会在后续的分析中出现一些问题。所以我们可以用 factor 函数，来将其转换成因子。 123&gt; test1$seed &lt;- factor(test1$seed)&gt; class(test1$seed)[1] "factor" 如果想要R不自动地将字符串转换成因子，可以 123456&gt; # 读数据的时候，设置&gt; test1 &lt;- read.table("rawdata/test1.txt",header = T,stringsAsFactors = F)&gt; &gt; # 自己构建数据框的时候，设置&gt; patientdata &lt;- data.frame(patientID, age, diabetes, status,names,stringsAsFactors = F)&gt; 参考文章： 《R语言实战》第二章 如何理解R中因子(factor)的概念 中猴子的回答]]></content>
      <categories>
        <category>生物医学统计课</category>
      </categories>
      <tags>
        <tag>R</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[给女朋友写的生统资料_Part1]]></title>
    <url>%2F2019%2F05%2F08%2F%E7%BB%99%E5%A5%B3%E6%9C%8B%E5%8F%8B%E5%86%99%E7%9A%84%E7%94%9F%E7%BB%9F%E8%B5%84%E6%96%99-Part1%2F</url>
    <content type="text"><![CDATA[因为深感生统的节奏比较快，可能女票跟不上节奏，所以写了一个简略的manual，只针对生统的一些相关操作，不涉及高深的R操作。如果大家觉得还要加什么东西，可以在下面留言。 前期准备 语言问题: 对于 R 或者 R studio来说，我非常建议把语言更改成英文。这样，在你报错的时候，比较方便去搜索 工作路径： 对于有R studio的来说，频繁地切换 setwd 和 getwd 可能不是一个很好的选择。所以我比较推荐新建一个Project，这样你每次你的任务都会是独立的。新建完Project之后你就可以把作业相关的数据放在你的Project里面。在后面读取的时候，就不用切换 setwd 或者打一大串目录了。 保存问题： 我比较推荐的是在Tools-Global Options—General那里，将Save Worksapce to .RData on exit那里设置为Never。这可能会导致你每次打开你的Project，变量都还得重新打一遍。但这可以保证你的代码的可重复性。 镜像及安装问题： 生统课上的如果包都很小，所以镜像设置其实是无所谓的。 如果想安装某个包的话，使用如下代码 12## 以安装pwr包为例，注意加引号#install.packages(&quot;pwr&quot;) 数据读取 生统课上用到的文件一般给的都是 txt 或者 csv 文件，这意味一般着只需要使用 read.table 这个命令来读取文件就可以了。 让我们先来看一下read.table这个函数怎么用。 1?read.table 不懂的时候寻求谷歌或者?+命令，是一个很好的习惯 你会发现read.table()里面跟了一大堆东西，其中跟我们可能相关的是 file：代表你要读的文件路径 header：表达你是否要添加表头，默认值是FALSE，我们一般要设置为TRUE sep：sep代表是你用什么样的形式来分割你读取的文件，一般生统的文件可能会以空格，制表符，逗号来分割。分别对应sep = " "，sep = ","，sep = "\t" 我们来尝试读一个文件 12test1 &lt;- read.table(&quot;rawdata/test1.txt&quot;,header = T)head(test1) 1234567## yield seed## 1 383 1## 2 406 1## 3 351 1## 4 400 1## 5 390 1## 6 361 1 这里我们用了 header = T ，这样我们的数据就会有表头，或者说列名了。即 yield 和 seed。 TRUE和T是等价的，同理FALSE和F也是等价的。 csv是本质上是用逗号分割的文件，所以我们在读的时候加上 sep = "," 即可。 head代表的是你只输出你数据的前几行。同理，tail输出后几行。 再次提醒一遍，感觉不懂命令是什么时候用?或者谷歌。 你还可以用row.names=1，来将第一列当作行名。]]></content>
      <categories>
        <category>生物医学统计课</category>
      </categories>
      <tags>
        <tag>R</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MACS2的原理介绍]]></title>
    <url>%2F2019%2F02%2F17%2FMACS2%E7%9A%84%E5%8E%9F%E7%90%86%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[泊松分布 泊松分布是统计与概率中重要的离散分布之一，泊松分布表示在一定的时间或空间内出现的事件个数，比如某一服务设施在一定时间内受到的服务请求的次数、DNA序列的变异数、汽车站台的等候人数。根据MACS的论文中所描述的，Chip-Seq实验中全基因组的reads分布恰好是符合泊松分布的。 泊松分布的概率分布为 \[ P(X = k)=\frac{e^{-\lambda}\lambda^{k}}{k!} \] 其中e代表的是自然常数，而\(\lambda\)是单位时间（或单位面积）内随机事件的平均发生率，比如在一定时间内某一服务设施受到的请求次数是5次。 另外，泊松分布实际上只有一个参数，即\(\lambda\)，其方差和期望也是\(\lambda\)。同时，随着\(\lambda\)的增加，图像分布会趋于对称。 参考资料 二项分布、泊松分布、正态分布的关系 泊松分布和指数分布：10分钟教程 wiki_泊松分布 MACS的算法概览 Adjusting read position based on fragment size distribution Chip-Seq的主要过程为：交联——超声破碎——特异性识别——测序。所以我们测序得到的片段就是我们转录因子结合位点周围的片段。需要注意的一点是，MACS软件出现的年代是2008年，那时候的测序读长都很短，大约50bp左右，且以单端测序为主，并没有真实反应DNA-蛋白结合片段的长度。所以说，我们如果拿测得的50bp去做reads数目的堆积，势必会与真实的结合位置有一定的偏移。事实上，测序的短reads会在真实的结合位置两侧形成双峰，如下图所A示。这也是MACS双峰模型构建的理论基础。 值得一提的是，像转录因子一类的蛋白与DNA，其结合位点比较narrow，所以双峰模型的构建是比较合理的。但像图B所示的，一些蛋白与DNA会产生较宽的结合区域（诸如一些组蛋白修饰），这时候双峰就不那么显著了。 更为麻烦的是，有时候会有一些混合的结合位点模式，比如Polll蛋白，其会在启动子区域结合，也会覆盖整个基因区域。 为了衡量真实的测序片段大小，d，MACS会粗略地以2倍的超声破碎片段长度作为window来鉴定初步的富集区域。为了避免重复区域或者PCR导致极端富集区域的影响，MACS会随机挑选1000个区域作为模型peak构建区域。这些区域的reads富集程度是基因组背景的10-30倍。对于每个区域的模型peak，MACS都会分离出对比到正链和负链上的reads，然后分别计算出这些reads的位置。从而分别构建出这个区域内的正负链上的模型peak，正负链上模型peak顶点之间距离就记为d。在d确定之后，所有的reads都会朝着3'的方向横移（shift）d/2的距离，从而更好地模拟出蛋白-DNA结合位点。 在2012年的Identifying ChIP-seq enrichment using MACS这篇文章中，作者也提到对于一些过度破碎或者有着很宽的结合位点情况，可能会造成算出来的d很小。对于这种情况，我们一般建议用一个特定的片段长度，而非是预测出来的d。 注意shift和extend的区别，在2008年原始的MACS文章中，作者用的是shift，而到了12年的文章，作者写错，写成了extend。当然，在MACS2中，这两种情况都存在了。 Calculate peak enrichment using local background normalization 基于先前已经调整位置的reads，MACS会在全基因组范围内以2d长度的window来寻找那些有显著富集的区域。有重叠的window会融合成一个候选区域。因为会有许多因素影响不同范围内的reads富集程度，所以MACS用了动态的\(\lambda_{local}\)参数来对于reads数目的富集进行泊松分布的建模。即MACS并不会用一个常数\(\lambda\)，而是用一个会在不同区域有变化的\(\lambda_{local}\)。动态参数值定义为 \[ \lambda_{local}=max(\lambda_{BG},[\lambda_{region},\lambda_{1k}],\lambda_{5k},\lambda_{10k}) \] \(\lambda_{BG}\)来自于全基因组的计算，\(\lambda_{region}\)则来自在control中的对应区域，剩下的\(\lambda_x\)则来自control中，以得到的候选区域为中心，1k，5k，10k范围内的区域计算。见下图 lambda 如果control不在，则local值只是在Chip的样本中计算，而region和1k值也会被舍弃。同时如果Chip-Seq和control的样本测序深度不同，MACS会默认地把测序深度更深的样本缩放。 关于\(\lambda\)以及p值这一步的计算可能需要看源代码才可以了解了。 但根据MACS2的wiki来说，似乎p值和\(\lambda\)的计算都是以单个碱基为单位考虑的。 基于泊松分布的模型，我们就可以以单尾检验，计算出p值了。MACS默认以p=1 x 10-5为阈值。 Estimating the empirical false discovery rate by exchanging ChIP-seq and control samples 这里MACS用的Chip和control的置换，从而检验出FDR值我并没有看懂。不过MACS2用的已经是Benjamini-Hochberg方法了，还是比较好懂的。 参考资料： Evaluation of Algorithm Performance in ChIP-Seq Peak Detection Model-based Analysis of ChIP-Seq (MACS) Identifying ChIP-seq enrichment using MACS In-depth-NGS-Data-Analysis-Course MACS2中的一些参数介绍 -f/--format FORMAT 可以接受多种格式参数，默认使用AUTO来检测格式。但并不能检测“BAMPE”或者“BEDPE”格式，即双端测序格式。所以，当你的数据是双端测序数据时，你应该用BAMPE或者BEDPE参数。当你设置成双端参数的时候，MACS2就会跳过建模计算d的那一步，而是直接用片段的insert size来建立堆积。 --extsize 如果使用这个参数，那么MACS就会使用你设置的数值，来把reads从5‘—3’补齐到你指定的数值。这个参数只有当--nomodel参数设置了，或者MACS建模失败，--fix-bimodal开启的时候才可以用。 --shift shift参数会先于extsize参数执行。如果你设置的数值为正，reads会从5‘—3’偏移，而数值为负，reads会从3'—5‘偏移。当格式为BAMPE或者BEDPE的时候，不能设置参数。 --broad 会放宽cutoff的阈值，然后把临近的区域结合起来，形成较宽的peak区域。与broad-cutoff参数是一起的，broad-cutoff参数默认为q-value的参数，为0.1。 有趣的是，shift后面数值如果为正，则正负链的reads会朝着中心偏移，如果后面数值为负，则正负链的reads会各自远离中心，即正链reads向左，负链reads向右。 给个例子： 1234567891011Original Reads:chr1 500 550 read1 . (+)chr1 700 750 read2 . (-)--shift -100chr1 400 450 read1 . (+)chr1 800 850 read2 . (-)--extsize 200chr1 400 600 read1 . (+)chr1 650 850 read2 . (-) 参考资料： MACS_github google_group 如何使用MACS进行peak calling]]></content>
      <categories>
        <category>算法原理</category>
      </categories>
      <tags>
        <tag>Bioinformatics</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我刷过的统计学资料]]></title>
    <url>%2F2019%2F02%2F13%2F%E6%88%91%E5%88%B7%E8%BF%87%E7%9A%84%E7%BB%9F%E8%AE%A1%E5%AD%A6%E8%B5%84%E6%96%99%2F</url>
    <content type="text"><![CDATA[感觉大家的统计学习兴趣都很浓，我这里也把我之前刷的一些统计资料说下。 说人话的统计学 在协和八微信公众号上连载。我认为这套教程是在学完基本的统计学知识之后，非常好的进阶教程。在看完这套教程后，很多之前学过的模糊知识点都会逐渐明晰。值得一提的是，两位作者都是有丰富数据分析经验的学者。可能也正是这样，这套教程并不局限于书本内容，更多地从实际出发。 女士品茶 在没有基本的统计学知识之前，不建议读这本书。可能你读了半天，会发现这整本书就讲了XX干了XX事。但等你的统计学到一定程度，再看这本书，就会有种越看越开心的感觉吧。不过这本书对于统计学本身功底的提升可能极为有限。 可汗学院公开课：统计学 总共85集，每集大约10分钟不到，老师讲的非常有趣，非常适合统计学入门。里面几乎不涉及公式推导，就讲了统计学中最常见的 随机变量、均值方差标准差、统计图表、概率密度、二项分布、泊松分布、正态分布、大数定律、中心极限定理、样本和抽样分布、参数估计、置信区间、伯努利分布、假设检验和p值、方差分析、回归分析等内容。 基本上刷完你就知道了大致的概念了。不过由于每集比较短，里面的解释可能比较含糊，但非常适合初步地过一遍。 深入浅出统计学 可以说是图文并茂吧，但有点太过于概括了。感觉适合快速地扫一遍。就我个人而言，这种过多地图片可能影响我思考问题了。。。 欧姆社的漫画统计学 额，怎么说呢，感觉适合没接触过统计学的，可能不太适合研究生了。毕竟漫画太多了。 概率论与数理统计（茆诗松版） 值得强推！讲的非常非常细，公式推导非常地详细，可能刷过这本才是真正意义上地去学统计了。不过感觉有点难刷，我看到最后很多公式都是跳着看的。 看完这本书你才发现Fisher、Pearson有多厉害。 概率论与数理统计（陈希孺版） 也非常推荐！但不建议当入门统计的去看这本书，最好地状态应该是先去看茆诗松版的，然后感觉有些概念模糊，觉得讲的不清楚去对照着看陈希孺院士这本书，两相映证，可能效果更好。 统计学习导论-基于R应用 这本书虽然叫统计学习导论，但实际上跟我们常见的统计关系不大。更多地是好像是机器学习的一些基础内容，但胜在公式推导不多，所以还是能看进去一点的。推荐和李程的基因组学课程一起看，你就会知道这里面的知识对于生命科学的研究的重要性了。 李程的基因组学生信技能树也推过的。 这本书就像是常见的统计学教科学的后续延伸，因为统计教科学一般都是以线性回归结束的，而这本书恰好是以线性回归开头的。 刷完这些课程的一些感悟 真正有帮助地可能还是教科书而不是比较入门的书籍，因为教科学会有严谨的推导，而一些入门书籍可能为了趣味性会放弃一些严谨性，而只告诉你一些描述性质的东西。 对于一些优秀的偏概括性质或者历史传记性质的书籍，比如《女士品茶》，《统计学七支柱》，《赤裸裸的统计学》，《数理统计学简史》等等，可能并不应该作为入门读物，而是应该作为刷完教科学之后再去翻阅的书。不然你看完这些书，可能最终留下的结论还是某年某月，某某人干了个什么事。又或者你在津津有味地看书的时候，看到作者提出的公式，会立刻跳过，而不是细细琢磨这个公式在这个背景下的作用。 有道是纸上得来终觉浅，可能下一步我的计划就是去努力地将自己学到的统计学知识跟自己平常遇到的生命科学结合起来，来更好地去学以致用。]]></content>
      <categories>
        <category>统计学习</category>
      </categories>
      <tags>
        <tag>Statistics</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mfuzz的使用]]></title>
    <url>%2F2019%2F01%2F06%2FMfuzz%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[最近在进行ATAC和RNA-Seq的联合分析，由于处理的材料是时间相关的，所以time-course也是一个可以分析的点。在一位刘潜老哥的帮助下，我找到了一篇靠谱熊 转录组时间序列数据处理 的文章，里面提到了mfuzz这个包。里面的软聚类的思想非常符合我的预期，然后就决定拿这个包进行我time-course的分析。为了更好的分析，我决定先翻译下这个包，了解下这个包的大致思想。 1 Overview 这部分是我偷懒的随便写的。。。。。。 感觉time-course的方法一般就是聚类。常见的聚类分为三种，分别是层次聚类（Hierarchical Clustering）、硬聚类（hard clustering）、软聚类（soft clustering）。层次聚类好像一般就是像热图那种。看了pheatmap的文档，感觉pheatmap就是层次聚类，当然你可以设置k_means，变成硬聚类。硬聚类常见的就是k-menas。软聚类就是我们这会要用到的这个包的核心思路。 2 Installation requirements 见Bioconductor的安装方法。 3 Data pre-processing 数据集是来源于酵母细胞循环表达数据。6178个基因，横跨160分钟的17个时间点。用的是芯片数据。 12345678&gt; head(yeast@assayData$exprs) cdc28_0 cdc28_10 cdc28_20 cdc28_30 cdc28_40 cdc28_50 cdc28_60 cdc28_70 cdc28_80 cdc28_90 cdc28_100 cdc28_110 cdc28_120 cdc28_130 cdc28_140 cdc28_150 cdc28_160YDR132C 0.19 0.30 -0.29 0.29 -0.31 0.23 0.20 -0.08 0.19 -0.51 0.00 -0.31 0.11 -0.02 0.20 0.36 -0.54YMR012W -0.15 -0.15 -0.04 -0.28 -0.39 0.03 0.22 0.04 -0.15 0.37 0.47 -0.10 -0.09 NA -0.04 0.07 0.19YLR214W 0.38 0.30 -0.68 -0.52 -0.43 -0.13 -0.17 0.26 -0.03 -0.34 -0.01 -0.20 0.10 NA 0.45 0.40 0.63YLR116W 0.17 0.06 -0.21 0.19 0.33 0.44 0.46 0.38 -0.15 -0.03 0.04 -0.42 -0.15 0.02 NA -0.51 -0.61YDR203W 0.85 -0.10 -0.56 -0.31 -0.43 0.00 -0.34 0.17 0.40 -0.37 0.15 0.24 0.24 0.17 -0.12 -0.02 0.02YEL059C-A 0.45 0.20 0.06 0.10 -0.21 -0.08 -0.27 -0.01 -0.29 0.41 -0.08 -0.22 -0.27 NA -0.30 0.25 0.26 3.1 Missing value 第一步，去除那些有超过25%数据缺失的基因。注意这些数据缺失值应该是设为NA。 12yeast.r &lt;- filter.NA(yeast, thres=0.25)49 genes excluded. 这里就如上面的数据一样，一行即一个基因有16个时间点的数据，如果16个时间点里面有25%，即4个时间点都是NA，则剔除这个基因。 123456&gt; nrow(yeast)Features 3000 &gt; nrow(yeast.r)Features 2951 Fuzzy c-means就像其他聚类算法一样，其并不允许有缺失值的存在。所以我们会对剩下那些缺失值（16个数据点里面就缺了1个2个那种）进行填充。用的是对应基因的平均表达值。 对于RNA-Seq来说，你可以加上一些pseudocount，比如0.01。 1yeast.f &lt;- fill.NA(yeast.r,mode="mean") 当然，你也可以用（weighted） k-nearest neighbour method。（mode='knn'/'wknn'）。这些方法相比较而言比上面这种简单的方法要好，但需要耗费更多的算力。 3.2 Filtering 许多已经出版的聚类分析包含过滤的步骤，从而来去除那些表达相对比较低的，或者表达不怎么变化的。通常来说，比较受欢迎的就是样本的标准差作为阈值。 1tmp &lt;- filter.std(yeast.f,min.std=0) 然而在基因低表达到高表达的过程中，变化是非常平缓的。所以给定阈值筛选并不一定是可靠的，可能是非常武断。因为现在并没有很多有说服力的筛选手段，所以我们还是避免对基因数据做提前的筛选。这可以避免损失一些有生物学重大意义的基因。 比如1,2,4,10,12,13,15。看起来变化很大，但方差可能并不如你想象中的那么大。 Standardisation 由于聚类是在欧几里德空间中进行的，因此基因的表达值被标准化为平均值为零，标准差为1。该步骤确保了在欧几里得空间中具有相似表达模式的基因是相互接近的。 1yeast.s &lt;- standardise(yeast.f) 重要的是，Mfuzz认为输入的表达数据是完全经过前期数据标准化的。standardise 并不能代替标准化步骤。注意差异：标准化是为了让不同的样品间可以比较，而Mufzz中standardisation则是让转录本或者基因间可以比较。 4 Soft clustering of gene expression data 聚类可以用来解释基因表达的调控机制。众所周知的，基因的表达并不是开和关的，而是一个逐渐变化的过程。一个聚类算法应该展现出一个基因有多么的符合dominant cluster pattern。软聚类应该是一个非常好的方法，因为其可以利用membership \(μ_{ij}\)衡量一个基因 i跟cluster j的关系。 其实就是说基因A跟每个cluster都有关系，无非是membership score的值不一样而已。 软聚类的mfuzz函数基于的是e1071包的fuzzy c-means算法。对于软过滤而言，聚类中心点\(c_j\)来源于所有聚类成员的权重值。在图中的membership值可以用mfuzz.plot来展现。你也可以用mfuzz.plot2来看，其会有更多的选项。 值得注意的是，clustering只会基于表达矩阵，不会使用phenoData的任何信息。还有，在mfuzz中重复会被当作是独立的信息，所以他们应该提前被算好平均值，或者放进不同的ExpressionSet对象里面。 12&gt; cl &lt;- mfuzz(yeast.s,c=16,m=1.25)&gt; mfuzz.plot(yeast.s,cl=cl,mfrow=c(4,4),time.labels=seq(0,160,10)) 123456789101112131415161718192021222324# center代表的应该是你选择的16个中心点的表达模式## 感觉可以用来画图&gt; head(cl$centers,2) cdc28_0 cdc28_10 cdc28_20 cdc28_30 cdc28_40 cdc28_50 cdc28_60 cdc28_70 cdc28_80 cdc28_90 cdc28_100 cdc28_110 cdc28_120 cdc28_130 cdc28_140 cdc28_150 cdc28_1601 0.1971169 -1.0925729 -1.6203551 -0.7961482 -0.33954720 -0.1567524 -0.05036767 0.08380756 0.5122518 0.3843354 0.4905732 0.437668149 0.4526805 0.3170533 0.2866267 0.2890568 0.60457312 -0.7393245 -0.5872038 0.2438611 -0.1883262 0.03321276 -1.0122666 -0.38203192 -0.47328266 -0.6289479 2.1494891 0.5371715 -0.001270464 -0.5672875 0.2288121 0.2331435 0.5896372 0.5646142# size代表的是各个聚类的基因数目 &gt; head(cl$size,2)[1] 175 244# cluster代表的是基因所属的membership score最高的那个簇&gt; head(cl$cluster,5)YDR132C YMR012W YLR214W YLR116W YDR203W 4 11 16 13 16 # membership代表的是每个基因对应16个簇的membership值&gt; head(cl$membership,5) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16YDR132C 0.014386854 0.0023657075 0.0478663840 0.47749014 0.007117060 0.070156647 0.010004348 0.051767933 0.01711759 0.028929516 0.0064926466 0.011933880 0.110039692 0.025007449 0.033967103 0.08535705YMR012W 0.082025023 0.1807366237 0.0088059459 0.00371571 0.012467968 0.002590922 0.127711735 0.007948114 0.06412901 0.004626184 0.3408675360 0.105343965 0.008278282 0.011112051 0.012020122 0.02762081YLR214W 0.130082565 0.0047176611 0.0041702207 0.06382311 0.001340277 0.004636745 0.013298969 0.043267912 0.21204674 0.016651050 0.0850329333 0.023956515 0.010243391 0.003459240 0.022271137 0.36100153YLR116W 0.002047923 0.0008467741 0.0412749579 0.01409627 0.002758020 0.034171711 0.001234725 0.002968499 0.00083482 0.003580831 0.0006540104 0.003016454 0.846273635 0.023517377 0.012508494 0.01021550YDR203W 0.083941355 0.0008482787 0.0008575124 0.02562416 0.001318053 0.004043468 0.001274160 0.032185727 0.12237271 0.002649867 0.0125075149 0.003545481 0.005389429 0.001504605 0.007198611 0.69473907 123mfuzz.plot(eset,cl,mfrow=c(1,1),colo,min.mem=0,time.labels,new.window=TRUE)colo可以设置颜色，min.mem可以设置membership的阈值 4.1 Setting of parameters for FCM clustering 对于fuzzy c-means来说，模糊值m和聚类数c必须提前设置好。对于m，我们应该选择一个可以防止随机数据聚类的值。值得注意的是，fuzzy 聚类可以遵守这样的准则，随机数据并不能被聚类。这相比于硬聚类（例如k-means）来说，是一个明显的优点。因为其即使在随机数据中，也可以检测到cluster。为了达到这一点，你可以使用下列选项： partcoef函数，来检测是否在某一特定的m设置下，随机数也会被聚类 或者直接计算 12&gt; m1 &lt;- mestimate(yeast.s)&gt; m1 # 1.15 设置一个合理的聚类值c是很有挑战性的，尤其是那些short time series，很有可能就会有overlapping clusters。我们可以设置一个最大的c值，大到最后出现了一个空的empty clusters（看 cselection函数） 12345678# 不太懂repeat值代表了什么&gt; cselection(yeast.s,m=1.25,crange=seq(4,32,4),repeats=5,visu=TRUE) c:4 c:8 c:12 c:16 c:20 c:24 c:28 c:32repeats:1 4 8 12 16 19 24 27 31repeats:2 4 8 12 16 20 23 28 30repeats:3 4 8 12 16 20 23 28 32repeats:4 4 8 12 16 20 24 28 31repeats:5 4 8 12 16 20 23 27 32 在cluster centroid之间最小距离\(D_{min}\) 也可以作为簇有效指数。在这里，我们可以检测不同的c值之间的\(D_{min}\)。我们可以预期D.min在达到最合适值之后，下降幅度会变低。你也可以选择 4.2 Cluster score Membership值也可以暗示两个向量之间的相关性。如果两个基因对于一个特定的cluster都有高的membership score，那么他们通常来说表达模式是相似的。我们对于高于阈值α的基因，叫做这个cluster的α-core。 membersip score的设置通常可以作为基因的后验筛选。我们可以用acore函数。 12tmp &lt;- acore(yeast.s,cl,min.acore = 0.5)# 生成的似乎是个列表，里面有16个。就可以知道每个簇里面含有的基因ID了。 5 Cluster stability FCM参数的变化也可以体现出cluster的稳健性。我们认为那些稳健的clusters具有某个特征，即在m的变化下，也只会展现出很小的变化。 12cl2 &lt;- mfuzz(yeast.s,c=16,m=1.35)mfuzz.plot(yeast.s,cl=cl2,mfrow=c(4,4),time.labels=seq(0,160,10)) 6 Global clustering structures 软聚类有趣的一点就是clusters之间的overlap或者coupling。在cluster k和l之间的coupling coefficient \(V_{kl}\) 可以定义为： \[ V_{kl}=\frac{1}{N}\sum^{N}_{i=1}{\mu_{ik}}{\mu_{il}} \] N是整个基因表达矩阵的数目。如果coupling值越低，说明两者的表达模式距离越远。如果越高，说明表达模式越相近。 12O &lt;- overlap(cl)Ptmp &lt;- overlap.plot(cl,over=O,thres=0.05) 7 Mfuzzgui - the graphical user interface for the Mfuzz pack-age mfuzz有图形化界面，不过我没去用。 小结 最近期末考试复习太忙了。。。。有空再加上点注意事项。]]></content>
      <categories>
        <category>软件的使用</category>
      </categories>
      <tags>
        <tag>Bioinformatics</tag>
      </tags>
  </entry>
</search>
